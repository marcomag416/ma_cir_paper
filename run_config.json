[
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t100",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 100,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t10",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t1",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 1,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_tlearnable",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 100,
    "learnable_temperature": true,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_q2i_sw_clip_b32_mscoco_lora_t100",
    "model_name": "CLIP_B32",
    "loss": "ma_q2i_sw",
    "dataset": "mscoco",
    "logit_scale": 100,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_q2i_sw_clip_b32_mscoco_lora_t10",
    "model_name": "CLIP_B32",
    "loss": "ma_q2i_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_q2i_sw_clip_b32_mscoco_lora_t1",
    "model_name": "CLIP_B32",
    "loss": "ma_q2i_sw",
    "dataset": "mscoco",
    "logit_scale": 1,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_q2i_sw_clip_b32_mscoco_lora_tlearnable",
    "model_name": "CLIP_B32",
    "loss": "ma_q2i_sw",
    "dataset": "mscoco",
    "logit_scale": 100,
    "learnable_temperature": true,
    "lr": 1e-4,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t100_th",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 100,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t10_th",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t10_th_freeproj",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_bi_sw_clip_b32_mscoco_lora_t10_th_freeproj",
    "model_name": "CLIP_B32",
    "loss": "unslerp_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_bi_sw_clip_b32_mscoco_lora_t10_th_freeproj_alpha05",
    "model_name": "CLIP_B32",
    "loss": "unslerp_bi_sw",
    "alpha_slerp": 0.5,
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_q2i_sw_clip_b32_mscoco_lora_t10_th_freeproj",
    "model_name": "CLIP_B32",
    "loss": "unslerp_q2i_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_q2i_clip_b32_mscoco_lora_t10_th_freeproj",
    "model_name": "CLIP_B32",
    "loss": "unslerp_q2i",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_q2i_sw_clip_b32_mscoco_lora_t10_th_freeproj_alpha05",
    "model_name": "CLIP_B32",
    "loss": "unslerp_q2i_sw",
    "alpha_slerp": 0.5,
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_q2t_sw_clip_b32_mscoco_lora_t10_th_freeproj",
    "model_name": "CLIP_B32",
    "loss": "unslerp_q2t_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t10_th_freeproj_FT",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "text",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t10_th_FT",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 10,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "all",
    "encoder_to_freeze": "text",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t1_th",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 1,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "ma_bi_sw_clip_b32_mscoco_lora_t01_th",
    "model_name": "CLIP_B32",
    "loss": "ma_bi_sw",
    "dataset": "mscoco",
    "logit_scale": 0.1,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_q2i_sw_clip_b32_mscoco_lora_t1_th_freeproj_alpha05",
    "model_name": "CLIP_B32",
    "loss": "unslerp_q2i_sw",
    "alpha_slerp": 0.5,
    "dataset": "mscoco",
    "logit_scale": 1,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    },
    {
    "name": "unslerp_bi_sw_clip_b32_mscoco_lora_t1_th_freeproj_alpha05",
    "model_name": "CLIP_B32",
    "loss": "unslerp_bi_sw",
    "alpha_slerp": 0.5,
    "dataset": "mscoco",
    "logit_scale": 1,
    "learnable_temperature": true,
    "lr": 1e-6,
    "scheduler": "none",
    "batch_size": 64,
    "num_epochs": 5,
    "weight_decay": 0.1,
    "warmup_ratio": 0.0,
    "use_lora": true,
    "adapter_type": "no_proj",
    "encoder_to_freeze": "none",
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "lora_rank": 16
    }


]